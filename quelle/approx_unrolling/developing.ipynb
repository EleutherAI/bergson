{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from quelle.approx_unrolling.utils import TensorDict\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "model_str = \"EleutherAI/pythia-14m\"\n",
    "step = 5000\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging gradient covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gradient = \"/root/quelle/quelle/approx_unrolling/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half/gradient_covariance.safetensors\"\n",
    "path_activation = \"/root/quelle/quelle/approx_unrolling/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half/activation_covariance.safetensors\"\n",
    "path_lambda_matrix = \"/root/quelle/quelle/approx_unrolling/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half/lambda_matrix.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [path_gradient, path_activation, path_lambda_matrix]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "gradient_covariance = TensorDict(load_file(path_gradient))\n",
    "activation_covariance = TensorDict(load_file(path_activation))\n",
    "lambda_matrix = TensorDict(load_file(path_lambda_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gpt_neox.layers.0.attention.dense', 'gpt_neox.layers.0.attention.query_key_value', 'gpt_neox.layers.0.mlp.dense_4h_to_h', 'gpt_neox.layers.0.mlp.dense_h_to_4h', 'gpt_neox.layers.1.attention.dense', 'gpt_neox.layers.1.attention.query_key_value', 'gpt_neox.layers.1.mlp.dense_4h_to_h', 'gpt_neox.layers.1.mlp.dense_h_to_4h', 'gpt_neox.layers.2.attention.dense', 'gpt_neox.layers.2.attention.query_key_value', 'gpt_neox.layers.2.mlp.dense_4h_to_h', 'gpt_neox.layers.2.mlp.dense_h_to_4h', 'gpt_neox.layers.3.attention.dense', 'gpt_neox.layers.3.attention.query_key_value', 'gpt_neox.layers.3.mlp.dense_4h_to_h', 'gpt_neox.layers.3.mlp.dense_h_to_4h', 'gpt_neox.layers.4.attention.dense', 'gpt_neox.layers.4.attention.query_key_value', 'gpt_neox.layers.4.mlp.dense_4h_to_h', 'gpt_neox.layers.4.mlp.dense_h_to_4h', 'gpt_neox.layers.5.attention.dense', 'gpt_neox.layers.5.attention.query_key_value', 'gpt_neox.layers.5.mlp.dense_4h_to_h', 'gpt_neox.layers.5.mlp.dense_h_to_4h'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_matrix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n",
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n",
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n",
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n",
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n",
      "model torch.Size([384, 128]) gradient torch.Size([384, 384]) activation torch.Size([129, 129]) lambda torch.Size([384, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 128]) gradient torch.Size([128, 128]) activation torch.Size([129, 129]) lambda torch.Size([128, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([512, 128]) gradient torch.Size([512, 512]) activation torch.Size([129, 129]) lambda torch.Size([512, 129])\n",
      "--------------------------------------------------\n",
      "model torch.Size([128, 512]) gradient torch.Size([128, 128]) activation torch.Size([513, 513]) lambda torch.Size([128, 513])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in model.named_modules():\n",
    "    if name[0] in lambda_matrix.keys():\n",
    "        print(\n",
    "            \"model\",\n",
    "            name[1].weight.shape,\n",
    "            \"gradient\",\n",
    "            gradient_covariance[name[0]].shape,\n",
    "            \"activation\",\n",
    "            activation_covariance[name[0]].shape,\n",
    "            \"lambda\",\n",
    "            lambda_matrix[name[0]].shape,\n",
    "        )\n",
    "\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'gpt_neox.layers.0.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.0.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.0.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.0.mlp.dense_h_to_4h': torch.Size([512, 512]), 'gpt_neox.layers.1.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.1.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.1.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.1.mlp.dense_h_to_4h': torch.Size([512, 512]), 'gpt_neox.layers.2.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.2.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.2.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.2.mlp.dense_h_to_4h': torch.Size([512, 512]), 'gpt_neox.layers.3.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.3.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.3.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.3.mlp.dense_h_to_4h': torch.Size([512, 512]), 'gpt_neox.layers.4.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.4.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.4.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.4.mlp.dense_h_to_4h': torch.Size([512, 512]), 'gpt_neox.layers.5.attention.dense': torch.Size([128, 128]), 'gpt_neox.layers.5.attention.query_key_value': torch.Size([384, 384]), 'gpt_neox.layers.5.mlp.dense_4h_to_h': torch.Size([128, 128]), 'gpt_neox.layers.5.mlp.dense_h_to_4h': torch.Size([512, 512])})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_covariance.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'gpt_neox.layers.0.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.0.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.0.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.0.mlp.dense_h_to_4h': torch.Size([129, 129]), 'gpt_neox.layers.1.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.1.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.1.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.1.mlp.dense_h_to_4h': torch.Size([129, 129]), 'gpt_neox.layers.2.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.2.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.2.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.2.mlp.dense_h_to_4h': torch.Size([129, 129]), 'gpt_neox.layers.3.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.3.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.3.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.3.mlp.dense_h_to_4h': torch.Size([129, 129]), 'gpt_neox.layers.4.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.4.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.4.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.4.mlp.dense_h_to_4h': torch.Size([129, 129]), 'gpt_neox.layers.5.attention.dense': torch.Size([129, 129]), 'gpt_neox.layers.5.attention.query_key_value': torch.Size([129, 129]), 'gpt_neox.layers.5.mlp.dense_4h_to_h': torch.Size([513, 513]), 'gpt_neox.layers.5.mlp.dense_h_to_4h': torch.Size([129, 129])})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_covariance.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'gpt_neox.layers.0.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.0.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.0.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.0.mlp.dense_h_to_4h': torch.Size([512, 129]), 'gpt_neox.layers.1.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.1.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.1.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.1.mlp.dense_h_to_4h': torch.Size([512, 129]), 'gpt_neox.layers.2.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.2.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.2.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.2.mlp.dense_h_to_4h': torch.Size([512, 129]), 'gpt_neox.layers.3.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.3.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.3.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.3.mlp.dense_h_to_4h': torch.Size([512, 129]), 'gpt_neox.layers.4.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.4.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.4.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.4.mlp.dense_h_to_4h': torch.Size([512, 129]), 'gpt_neox.layers.5.attention.dense': torch.Size([128, 129]), 'gpt_neox.layers.5.attention.query_key_value': torch.Size([384, 129]), 'gpt_neox.layers.5.mlp.dense_4h_to_h': torch.Size([128, 513]), 'gpt_neox.layers.5.mlp.dense_h_to_4h': torch.Size([512, 129])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_matrix.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0 diff: 0.0\n",
      "Loss 1 diff: 0.0\n",
      "Loss 2 diff: 0.0\n",
      "Loss 3 diff: 0.0\n",
      "Loss 4 diff: 0.0\n",
      "Loss 5 diff: 0.0\n",
      "Loss 6 diff: 0.0\n",
      "Loss 7 diff: 0.0\n",
      "Loss 8 diff: 0.0\n",
      "Loss 9 diff: 0.0\n",
      "Loss 10 diff: 0.0\n",
      "Loss 11 diff: 0.0\n",
      "Loss 12 diff: 0.0\n",
      "Loss 13 diff: 0.0\n",
      "Loss 14 diff: 0.0\n",
      "Loss 15 diff: 0.0\n",
      "Loss 16 diff: 0.0\n",
      "Loss 17 diff: 0.0\n",
      "Loss 18 diff: 0.0\n",
      "Loss 19 diff: 0.0\n",
      "Loss 20 diff: 0.0\n",
      "Loss 21 diff: 0.0\n",
      "Loss 22 diff: 0.0\n",
      "Loss 23 diff: 0.0\n",
      "Loss 24 diff: 0.0\n",
      "Loss 25 diff: 0.0\n",
      "Loss 26 diff: 0.0\n",
      "Loss 27 diff: 0.0\n",
      "Loss 28 diff: 0.0\n",
      "Loss 29 diff: 0.0\n",
      "Loss 30 diff: 0.0\n",
      "Loss 31 diff: 0.0\n",
      "Loss 32 diff: 0.0\n",
      "Loss 33 diff: 0.0\n",
      "Loss 34 diff: 0.0\n",
      "Loss 35 diff: 0.0\n",
      "Loss 36 diff: 0.0\n",
      "Loss 37 diff: 0.0\n",
      "Loss 38 diff: 0.0\n",
      "Loss 39 diff: 0.0\n",
      "Loss 40 diff: 0.0\n",
      "Loss 41 diff: 0.0\n",
      "Loss 42 diff: 0.0\n",
      "Loss 43 diff: 0.0\n",
      "Loss 44 diff: 0.0\n",
      "Loss 45 diff: 0.0\n",
      "Loss 46 diff: 0.0\n",
      "Loss 47 diff: 0.0\n",
      "Loss 48 diff: 0.0\n",
      "Loss 49 diff: 0.0\n",
      "Loss 50 diff: 0.0\n",
      "Loss 51 diff: 0.0\n",
      "Loss 52 diff: 0.0\n",
      "Loss 53 diff: 0.0\n",
      "Loss 54 diff: 0.0\n",
      "Loss 55 diff: 0.0\n",
      "Loss 56 diff: 0.0\n",
      "Loss 57 diff: 0.0\n",
      "Loss 58 diff: 0.0\n",
      "Loss 59 diff: 0.0\n",
      "Loss 60 diff: 0.0\n",
      "Loss 61 diff: 0.0\n",
      "Loss 62 diff: 0.0\n",
      "Loss 63 diff: 0.0\n",
      "Loss 64 diff: 0.0\n",
      "Loss 65 diff: 0.0\n",
      "Loss 66 diff: 0.0\n",
      "Loss 67 diff: 0.0\n",
      "Loss 68 diff: 0.0\n",
      "Loss 69 diff: 0.0\n",
      "Loss 70 diff: 0.0\n",
      "Loss 71 diff: 0.0\n",
      "Loss 72 diff: 0.0\n",
      "Loss 73 diff: 0.0\n",
      "Loss 74 diff: 0.0\n",
      "Loss 75 diff: 0.0\n",
      "Loss 76 diff: 0.0\n",
      "Loss 77 diff: 0.0\n",
      "Loss 78 diff: 0.0\n",
      "Loss 79 diff: 0.0\n",
      "Loss 80 diff: 0.0\n",
      "Loss 81 diff: 0.0\n",
      "Loss 82 diff: 0.0\n",
      "Loss 83 diff: 0.0\n",
      "Loss 84 diff: 0.0\n",
      "Loss 85 diff: 0.0\n",
      "Loss 86 diff: 0.0\n",
      "Loss 87 diff: 0.0\n",
      "Loss 88 diff: 0.0\n",
      "Loss 89 diff: 0.0\n",
      "Loss 90 diff: 0.0\n",
      "Loss 91 diff: 0.0\n",
      "Loss 92 diff: 0.0\n",
      "Loss 93 diff: 0.0\n",
      "Loss 94 diff: 0.0\n",
      "Loss 95 diff: 0.0\n",
      "Loss 96 diff: 0.0\n",
      "Loss 97 diff: 0.0\n",
      "Loss 98 diff: 0.0\n",
      "Loss 99 diff: 0.0\n",
      "Loss 100 diff: 0.0\n",
      "Loss 101 diff: 0.0\n",
      "Loss 102 diff: 0.0\n",
      "Loss 103 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(104):\n",
    "    loss_1 = torch.load(os.path.join(path_1, f\"loss_{i}.pt\"))\n",
    "    loss_2 = torch.load(os.path.join(path_2, f\"loss_{i}.pt\"))\n",
    "    diff = loss_1 - loss_2\n",
    "    print(f\"Loss {i} diff: {diff.abs().mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exammining the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comparison(path_1, path_2):\n",
    "    files_1 = os.listdir(path_1)\n",
    "    files_2 = os.listdir(path_2)\n",
    "\n",
    "    for file_1 in files_1:\n",
    "        if file_1 in files_2:\n",
    "            if file_1.endswith(\".safetensors\"):\n",
    "                tensor_1 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_1, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                tensor_2 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_2, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                diff = tensor_1 - tensor_2\n",
    "                all_close = tensor_1.allclose(tensor_2, rtol=1e-5, atol=1e-5)\n",
    "                all_close_values = all(all_close.values())\n",
    "                if not all_close_values:\n",
    "                    print(file_1)\n",
    "                    print(\"Differences found:\")\n",
    "                    print(diff.max())\n",
    "                # check if all_close has any key that is False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"/root/quelle/tests/caches/cache_1/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\"\n",
    "path_2 = \"/root/quelle/tests/caches/cache_2/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_covariance.safetensors\n",
      "Differences found:\n",
      "TensorDict({'gpt_neox.layers.0.attention.dense': tensor(8192., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.attention.query_key_value': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.mlp.dense_4h_to_h': tensor(8192., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.mlp.dense_h_to_4h': tensor(1024., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.attention.dense': tensor(4096., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.attention.query_key_value': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.mlp.dense_4h_to_h': tensor(4096., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.mlp.dense_h_to_4h': tensor(512., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.attention.dense': tensor(2048., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.attention.query_key_value': tensor(256., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.mlp.dense_4h_to_h': tensor(2048., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.mlp.dense_h_to_4h': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.attention.dense': tensor(512., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.attention.query_key_value': tensor(32., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.mlp.dense_4h_to_h': tensor(512., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.mlp.dense_h_to_4h': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.attention.dense': tensor(64., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.attention.query_key_value': tensor(1., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.mlp.dense_4h_to_h': tensor(64., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.mlp.dense_h_to_4h': tensor(32., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.attention.dense': tensor(0., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.attention.query_key_value': tensor(0.0625, device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.mlp.dense_4h_to_h': tensor(0., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.mlp.dense_h_to_4h': tensor(0., device='cuda:0', dtype=torch.bfloat16)})\n"
     ]
    }
   ],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_covariance.safetensors\n",
      "Differences found:\n",
      "TensorDict({'gpt_neox.layers.0.attention.dense': tensor(32768., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.attention.query_key_value': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.mlp.dense_4h_to_h': tensor(32768., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.0.mlp.dense_h_to_4h': tensor(1024., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.attention.dense': tensor(4096., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.attention.query_key_value': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.mlp.dense_4h_to_h': tensor(4096., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.1.mlp.dense_h_to_4h': tensor(512., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.attention.dense': tensor(2048., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.attention.query_key_value': tensor(1024., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.mlp.dense_4h_to_h': tensor(2048., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.2.mlp.dense_h_to_4h': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.attention.dense': tensor(256., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.attention.query_key_value': tensor(32., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.mlp.dense_4h_to_h': tensor(256., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.3.mlp.dense_h_to_4h': tensor(128., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.attention.dense': tensor(256., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.attention.query_key_value': tensor(4., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.mlp.dense_4h_to_h': tensor(256., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.4.mlp.dense_h_to_4h': tensor(32., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.attention.dense': tensor(0., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.attention.query_key_value': tensor(0.0156, device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.mlp.dense_4h_to_h': tensor(0., device='cuda:0', dtype=torch.bfloat16), 'gpt_neox.layers.5.mlp.dense_h_to_4h': tensor(0., device='cuda:0', dtype=torch.bfloat16)})\n"
     ]
    }
   ],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = TensorDict(\n",
    "    load_file(os.path.join(path_1, \"gradient_covariance.safetensors\"), device=\"cuda\")\n",
    ")\n",
    "tensor_2 = TensorDict(\n",
    "    load_file(os.path.join(path_2, \"gradient_covariance.safetensors\"), device=\"cuda\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict({'gpt_neox.layers.0.attention.dense': tensor(774, device='cuda:0'), 'gpt_neox.layers.0.attention.query_key_value': tensor(38502, device='cuda:0'), 'gpt_neox.layers.0.mlp.dense_4h_to_h': tensor(774, device='cuda:0'), 'gpt_neox.layers.0.mlp.dense_h_to_4h': tensor(254961, device='cuda:0'), 'gpt_neox.layers.1.attention.dense': tensor(7358, device='cuda:0'), 'gpt_neox.layers.1.attention.query_key_value': tensor(13118, device='cuda:0'), 'gpt_neox.layers.1.mlp.dense_4h_to_h': tensor(7358, device='cuda:0'), 'gpt_neox.layers.1.mlp.dense_h_to_4h': tensor(215460, device='cuda:0'), 'gpt_neox.layers.2.attention.dense': tensor(1382, device='cuda:0'), 'gpt_neox.layers.2.attention.query_key_value': tensor(50052, device='cuda:0'), 'gpt_neox.layers.2.mlp.dense_4h_to_h': tensor(1382, device='cuda:0'), 'gpt_neox.layers.2.mlp.dense_h_to_4h': tensor(10443, device='cuda:0'), 'gpt_neox.layers.3.attention.dense': tensor(2395, device='cuda:0'), 'gpt_neox.layers.3.attention.query_key_value': tensor(68145, device='cuda:0'), 'gpt_neox.layers.3.mlp.dense_4h_to_h': tensor(2395, device='cuda:0'), 'gpt_neox.layers.3.mlp.dense_h_to_4h': tensor(155439, device='cuda:0'), 'gpt_neox.layers.4.attention.dense': tensor(12139, device='cuda:0'), 'gpt_neox.layers.4.attention.query_key_value': tensor(12711, device='cuda:0'), 'gpt_neox.layers.4.mlp.dense_4h_to_h': tensor(12139, device='cuda:0'), 'gpt_neox.layers.4.mlp.dense_h_to_4h': tensor(42294, device='cuda:0'), 'gpt_neox.layers.5.attention.dense': tensor(0, device='cuda:0'), 'gpt_neox.layers.5.attention.query_key_value': tensor(39439, device='cuda:0'), 'gpt_neox.layers.5.mlp.dense_4h_to_h': tensor(0, device='cuda:0'), 'gpt_neox.layers.5.mlp.dense_h_to_4h': tensor(0, device='cuda:0')})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor_1 - tensor_2).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neox.layers.0.attention.dense 65536.0 -32768.0 4.15625 1640.0\n",
      "gpt_neox.layers.0.attention.query_key_value 64.0 -64.0 0.0032806396484375 1.15625\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h 65536.0 -32768.0 4.15625 1640.0\n",
      "gpt_neox.layers.0.mlp.dense_h_to_4h 4096.0 -2048.0 0.134765625 59.0\n",
      "gpt_neox.layers.1.attention.dense 16384.0 -8192.0 -1.3984375 584.0\n",
      "gpt_neox.layers.1.attention.query_key_value 128.0 -128.0 0.0040283203125 1.375\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h 16384.0 -8192.0 -1.3984375 584.0\n",
      "gpt_neox.layers.1.mlp.dense_h_to_4h 2048.0 -2048.0 -0.0198974609375 24.0\n",
      "gpt_neox.layers.2.attention.dense 2048.0 -4096.0 0.5859375 147.0\n",
      "gpt_neox.layers.2.attention.query_key_value 2048.0 -512.0 0.02783203125 8.9375\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h 2048.0 -4096.0 0.5859375 147.0\n",
      "gpt_neox.layers.2.mlp.dense_h_to_4h 256.0 -512.0 -0.0172119140625 7.75\n",
      "gpt_neox.layers.3.attention.dense 512.0 -1024.0 -0.001220703125 17.375\n",
      "gpt_neox.layers.3.attention.query_key_value 128.0 -32.0 0.000263214111328125 0.486328125\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h 512.0 -1024.0 -0.001220703125 17.375\n",
      "gpt_neox.layers.3.mlp.dense_h_to_4h 512.0 -128.0 -0.0021820068359375 2.21875\n",
      "gpt_neox.layers.4.attention.dense 256.0 -10.0 0.030029296875 2.828125\n",
      "gpt_neox.layers.4.attention.query_key_value 64.0 -8.0 0.000888824462890625 0.240234375\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h 256.0 -10.0 0.030029296875 2.828125\n",
      "gpt_neox.layers.4.mlp.dense_h_to_4h 32.0 -32.0 -0.0008087158203125 0.2060546875\n",
      "gpt_neox.layers.5.attention.dense 0.0 0.0 0.0 0.0\n",
      "gpt_neox.layers.5.attention.query_key_value 0.015625 -0.0625 -1.7583370208740234e-06 0.00029754638671875\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h 0.0 0.0 0.0 0.0\n",
      "gpt_neox.layers.5.mlp.dense_h_to_4h 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in (tensor_1 - tensor_2).items():\n",
    "    print(k, v.max().item(), v.min().item(), v.mean().item(), v.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neox.layers.0.attention.dense\n",
      "tensor(196608., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.0.attention.query_key_value\n",
      "tensor(768., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.0.mlp.dense_4h_to_h\n",
      "tensor(196608., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.0.mlp.dense_h_to_4h\n",
      "tensor(12288., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.1.attention.dense\n",
      "tensor(163840., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.1.attention.query_key_value\n",
      "tensor(512., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.1.mlp.dense_4h_to_h\n",
      "tensor(163840., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.1.mlp.dense_h_to_4h\n",
      "tensor(8192., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.2.attention.dense\n",
      "tensor(98304., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.2.attention.query_key_value\n",
      "tensor(32768., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.2.mlp.dense_4h_to_h\n",
      "tensor(98304., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.2.mlp.dense_h_to_4h\n",
      "tensor(4096., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.3.attention.dense\n",
      "tensor(32768., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.3.attention.query_key_value\n",
      "tensor(768., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.3.mlp.dense_4h_to_h\n",
      "tensor(32768., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.3.mlp.dense_h_to_4h\n",
      "tensor(2048., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.4.attention.dense\n",
      "tensor(24576., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.4.attention.query_key_value\n",
      "tensor(256., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.4.mlp.dense_4h_to_h\n",
      "tensor(24576., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.4.mlp.dense_h_to_4h\n",
      "tensor(2048., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.5.attention.dense\n",
      "tensor(20480., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.5.attention.query_key_value\n",
      "tensor(1024., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.5.mlp.dense_4h_to_h\n",
      "tensor(20480., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n",
      "gpt_neox.layers.5.mlp.dense_h_to_4h\n",
      "tensor(1280., device='cuda:0', dtype=torch.bfloat16)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "d = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/quelle/quelle/approx_unrolling/.models/EleutherAI/pythia-14m/segment_0/influence_results/factors_ekfac_half/average_gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "d_2 = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/quelle/.models/EleutherAI/influence_results/factors_ekfac_half/gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "diff = d - d_2\n",
    "\n",
    "for k, v in diff.items():\n",
    "    if v.max() < 1e-5:\n",
    "        continue\n",
    "    print(k)\n",
    "    print(v.max())\n",
    "    print(\"----\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 15335424\n",
    "# determine prime decomposition of number\n",
    "number / 7488\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quelle.approx_unrolling.utils import TensorDict\n",
    "\n",
    "\n",
    "d = TensorDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [d, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'TensorDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'int' and 'TensorDict'"
     ]
    }
   ],
   "source": [
    "sum(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half\"\n",
    "\n",
    "# list of all subfolders or files\n",
    "import os\n",
    "\n",
    "subfolders = []\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    for dirname in dirnames:\n",
    "        subfolders.append(os.path.join(dirpath, dirname))\n",
    "    for filename in filenames:\n",
    "        subfolders.append(os.path.join(dirpath, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames\n",
    "filenames_json = [f for f in subfolders if f.endswith(\".json\")]\n",
    "filesnames_safetensors = [f for f in subfolders if f.endswith(\".safetensors\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/factor_arguments.json',\n",
       " '/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/covariance_dataset_metadata.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy': 'ekfac',\n",
       " 'use_empirical_fisher': False,\n",
       " 'amp_dtype': 'torch.bfloat16',\n",
       " 'amp_scale': 65536.0,\n",
       " 'has_shared_parameters': False,\n",
       " 'covariance_max_examples': 100000,\n",
       " 'covariance_data_partitions': 1,\n",
       " 'covariance_module_partitions': 1,\n",
       " 'activation_covariance_dtype': 'torch.bfloat16',\n",
       " 'gradient_covariance_dtype': 'torch.bfloat16',\n",
       " 'eigendecomposition_dtype': 'torch.float64',\n",
       " 'lambda_max_examples': 100000,\n",
       " 'lambda_data_partitions': 1,\n",
       " 'lambda_module_partitions': 1,\n",
       " 'use_iterative_lambda_aggregation': False,\n",
       " 'offload_activations_to_cpu': False,\n",
       " 'per_sample_gradient_dtype': 'torch.bfloat16',\n",
       " 'lambda_dtype': 'torch.bfloat16'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_file = filenames_json[0]\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/activation_covariance.safetensors',\n",
       " '/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/gradient_covariance.safetensors',\n",
       " '/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/num_activation_covariance_processed.safetensors',\n",
       " '/home/louis/quelle/quelle/approx_unrolling/influence_results/wikitext/factors_ekfac_half/num_gradient_covariance_processed.safetensors']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesnames_safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lm_head', 'transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj', 'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj', 'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj', 'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj', 'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj', 'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj', 'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj', 'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj', 'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj', 'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj', 'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj'])\n",
      "dict_keys(['lm_head', 'transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj', 'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj', 'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj', 'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj', 'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj', 'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj', 'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj', 'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj', 'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj', 'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj', 'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj'])\n",
      "dict_keys(['lm_head', 'transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj', 'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj', 'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj', 'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj', 'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj', 'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj', 'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj', 'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj', 'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj', 'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj', 'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj'])\n",
      "dict_keys(['lm_head', 'transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj', 'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj', 'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj', 'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj', 'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj', 'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj', 'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj', 'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj', 'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj', 'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj', 'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj'])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "for i in range(len(filesnames_safetensors)):\n",
    "    path = filesnames_safetensors[i]\n",
    "    tensors = {}\n",
    "    with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "        for k in f.keys():\n",
    "            tensors[k] = f.get_tensor(k)\n",
    "    print(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = filesnames_safetensors[-2]\n",
    "with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_2 = torch.load(\"/home/louis/quelle/quelle/approx_unrolling/checkpoints/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = model.state_dict()\n",
    "\n",
    "all_mlps = {k: v for k, v in all_weights.items() if \"mlp\" in k}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_keys = [m[0] for m in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_attention = True\n",
    "track_mlp = True\n",
    "total_modules = []\n",
    "for m in module_keys:\n",
    "    if \"dropout\" in m.lower() or \"layernorm\" in m.lower():\n",
    "        continue\n",
    "\n",
    "    if \"attention\" in m.lower() and track_attention:\n",
    "        total_modules.append(m)\n",
    "    if \"mlp\" in m.lower() and track_mlp:\n",
    "        total_modules.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdist\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnccl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m dist.get_rank()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quelle/.venv/lib/python3.13/site-packages/torch/distributed/c10d_logger.py:81\u001b[39m, in \u001b[36m_exception_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     83\u001b[39m         msg_dict = _get_msg_dict(func.\u001b[34m__name__\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quelle/.venv/lib/python3.13/site-packages/torch/distributed/c10d_logger.py:95\u001b[39m, in \u001b[36m_time_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _WaitCounter(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpytorch.wait_counter.c10d.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m).guard():\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         func_return = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func_return\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quelle/.venv/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:1710\u001b[39m, in \u001b[36minit_process_group\u001b[39m\u001b[34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[39m\n\u001b[32m   1706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1707\u001b[39m     rendezvous_iterator = rendezvous(\n\u001b[32m   1708\u001b[39m         not_none(init_method), rank, world_size, timeout=timeout\n\u001b[32m   1709\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1710\u001b[39m     store, rank, world_size = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1711\u001b[39m     store.set_timeout(timeout)\n\u001b[32m   1713\u001b[39m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[32m   1714\u001b[39m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quelle/.venv/lib/python3.13/site-packages/torch/distributed/rendezvous.py:267\u001b[39m, in \u001b[36m_env_rendezvous_handler\u001b[39m\u001b[34m(url, timeout, **kwargs)\u001b[39m\n\u001b[32m    265\u001b[39m     rank = \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[33m\"\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     rank = \u001b[38;5;28mint\u001b[39m(\u001b[43m_get_env_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRANK\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mworld_size\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m query_dict:\n\u001b[32m    270\u001b[39m     world_size = \u001b[38;5;28mint\u001b[39m(query_dict[\u001b[33m\"\u001b[39m\u001b[33mworld_size\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/quelle/.venv/lib/python3.13/site-packages/torch/distributed/rendezvous.py:252\u001b[39m, in \u001b[36m_env_rendezvous_handler.<locals>._get_env_or_raise\u001b[39m\u001b[34m(env_var)\u001b[39m\n\u001b[32m    250\u001b[39m env_val = os.environ.get(env_var, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_val:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _env_error(env_var)\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_val\n",
      "\u001b[31mValueError\u001b[39m: Error initializing torch.distributed using env:// rendezvous: environment variable RANK expected, but not set"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.wikitext.pipeline import get_wikitext_dataset\n",
    "\n",
    "train_dataset = get_wikitext_dataset(\n",
    "    split=\"eval_train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train_dataset\n",
    "sample = train_dataset[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quelle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
