{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from bergson.approx_unrolling.utils import TensorDict\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(\n",
    "    1,\n",
    "    dtype=torch.float16,\n",
    "    requires_grad=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "model_str = \"EleutherAI/pythia-14m\"\n",
    "step = 5000\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_str,\n",
    "    revision=f\"step{step}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exammining the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comparison(path_1, path_2):\n",
    "    files_1 = os.listdir(path_1)\n",
    "    files_2 = os.listdir(path_2)\n",
    "\n",
    "    for file_1 in files_1:\n",
    "        if file_1 in files_2:\n",
    "            if file_1.endswith(\".safetensors\"):\n",
    "                tensor_1 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_1, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                tensor_2 = TensorDict(\n",
    "                    load_file(\n",
    "                        os.path.join(path_2, file_1),\n",
    "                        device=\"cuda\",\n",
    "                    )\n",
    "                )\n",
    "                diff = tensor_1 - tensor_2\n",
    "                all_close = tensor_1.allclose(tensor_2, rtol=1e-5, atol=1e-5)\n",
    "                all_close_values = all(all_close.values())\n",
    "                if not all_close_values:\n",
    "                    print(file_1)\n",
    "                    print(\"Differences found:\")\n",
    "                    print(diff.max())\n",
    "                # check if all_close has any key that is False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = \"/root/bergson/tests/caches/cache_1/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\"\n",
    "path_2 = \"/root/bergson/tests/caches/cache_2/.models/EleutherAI/pythia-14m/checkpoint_1000/influence_results/factors_ekfac_half\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comparison(path_2, path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = TensorDict(load_file(os.path.join(path_1, \"gradient_covariance.safetensors\"), device=\"cuda\"))\n",
    "tensor_2 = TensorDict(load_file(os.path.join(path_2, \"gradient_covariance.safetensors\"), device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor_1 - tensor_2).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in (tensor_1 - tensor_2).items():\n",
    "    print(k, v.max().item(), v.min().item(), v.mean().item(), v.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/bergson/bergson/approx_unrolling/.models/EleutherAI/pythia-14m/segment_0/influence_results/factors_ekfac_half/average_gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "d_2 = TensorDict(\n",
    "    load_file(\n",
    "        \"/root/bergson/.models/EleutherAI/influence_results/factors_ekfac_half/gradient_covariance.safetensors\",\n",
    "        device=\"cuda\",\n",
    "    )\n",
    ")\n",
    "\n",
    "diff = d - d_2\n",
    "\n",
    "for k, v in diff.items():\n",
    "    if v.max() < 1e-5:\n",
    "        continue\n",
    "    print(k)\n",
    "    print(v.max())\n",
    "    print(\"----\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 15335424\n",
    "# determine prime decomposition of number\n",
    "number / 7488\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bergson.approx_unrolling.utils import TensorDict\n",
    "\n",
    "\n",
    "d = TensorDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [d, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/louis/bergson/bergson/approx_unrolling/influence_results/wikitext/factors_ekfac_half\"\n",
    "\n",
    "# list of all subfolders or files\n",
    "import os\n",
    "\n",
    "subfolders = []\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    for dirname in dirnames:\n",
    "        subfolders.append(os.path.join(dirpath, dirname))\n",
    "    for filename in filenames:\n",
    "        subfolders.append(os.path.join(dirpath, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames\n",
    "filenames_json = [f for f in subfolders if f.endswith(\".json\")]\n",
    "filesnames_safetensors = [f for f in subfolders if f.endswith(\".safetensors\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file = filenames_json[0]\n",
    "with open(json_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesnames_safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "for i in range(len(filesnames_safetensors)):\n",
    "    path = filesnames_safetensors[i]\n",
    "    tensors = {}\n",
    "    with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "        for k in f.keys():\n",
    "            tensors[k] = f.get_tensor(k)\n",
    "    print(tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = filesnames_safetensors[-2]\n",
    "with safe_open(path, framework=\"pt\", device=0) as f:\n",
    "    for k in f.keys():\n",
    "        tensors[k] = f.get_tensor(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_2 = torch.load(\"/home/louis/bergson/bergson/approx_unrolling/checkpoints/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = model.state_dict()\n",
    "\n",
    "all_mlps = {k: v for k, v in all_weights.items() if \"mlp\" in k}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_mlps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_keys = [m[0] for m in model.named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_attention = True\n",
    "track_mlp = True\n",
    "total_modules = []\n",
    "for m in module_keys:\n",
    "    if \"dropout\" in m.lower() or \"layernorm\" in m.lower():\n",
    "        continue\n",
    "\n",
    "    if \"attention\" in m.lower() and track_attention:\n",
    "        total_modules.append(m)\n",
    "    if \"mlp\" in m.lower() and track_mlp:\n",
    "        total_modules.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.wikitext.pipeline import get_wikitext_dataset\n",
    "\n",
    "train_dataset = get_wikitext_dataset(\n",
    "    split=\"eval_train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train_dataset\n",
    "sample = train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOM debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Memory Timeline ===\n",
      "Time (s) | Action | Memory (GB) |             Location\n",
      "------------------------------------------------------------\n",
      "\n",
      "Peak memory usage: 0.000 GB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def analyze_gpu_memory_trace(pickle_file):\n",
    "    with open(pickle_file, \"rb\") as f:\n",
    "        snapshot = pickle.load(f)\n",
    "\n",
    "    print(\"=== GPU Memory Timeline ===\")\n",
    "    allocations = []\n",
    "\n",
    "    for trace in snapshot.get(\"traces\", []):\n",
    "        if trace.get(\"action\") in [\"alloc\", \"free\"]:\n",
    "            time_s = trace.get(\"ts\", 0) / 1000000\n",
    "            size_gb = trace.get(\"size\", 0) / (1024**3)\n",
    "            action = trace.get(\"action\")\n",
    "\n",
    "            # Get user code location\n",
    "            frames = trace.get(\"frames\", [])\n",
    "            user_frame = None\n",
    "            for frame in frames:\n",
    "                filename = frame.get(\"filename\", \"\")\n",
    "                if not any(skip in filename for skip in [\"torch\", \"cuda\", \"python\", \"site-packages\"]):\n",
    "                    user_frame = frame\n",
    "                    break\n",
    "\n",
    "            if user_frame and size_gb > 0.001:  # > 1MB\n",
    "                allocations.append(\n",
    "                    {\n",
    "                        \"time\": time_s,\n",
    "                        \"size_gb\": size_gb,\n",
    "                        \"action\": action,\n",
    "                        \"file\": user_frame.get(\"filename\", \"\").split(\"/\")[-1],\n",
    "                        \"line\": user_frame.get(\"line\", \"?\"),\n",
    "                        \"function\": user_frame.get(\"name\", \"unknown\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    # Sort by time\n",
    "    allocations.sort(key=lambda x: x[\"time\"])\n",
    "\n",
    "    print(f\"{'Time (s)':>8} | {'Action':>5} | {'Memory (GB)':>10} | {'Location':>20}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    running_total = 0\n",
    "    for alloc in allocations:\n",
    "        if alloc[\"action\"] == \"alloc\":\n",
    "            running_total += alloc[\"size_gb\"]\n",
    "        else:\n",
    "            running_total -= alloc[\"size_gb\"]\n",
    "\n",
    "        location = f\"{alloc['file']}:{alloc['line']}\"\n",
    "        print(f\"{alloc['time']:8.3f} | {alloc['action']:>5} | {alloc['size_gb']:10.3f} | {location:>20}\")\n",
    "\n",
    "    print(f\"\\nPeak memory usage: {max(running_total, 0):.3f} GB\")\n",
    "\n",
    "\n",
    "# Use it\n",
    "\n",
    "snapshot_path = \"/root/quelle/bergson/approx_unrolling/auto_memory_trace.pickle\"\n",
    "analyze_gpu_memory_trace(snapshot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test tensor...\n",
      "Test tensor created, memory allocated: 0.004 GB\n",
      "Snapshot contains 0 traces\n",
      "Snapshot dumped to file\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Enable recording\n",
    "torch.cuda.memory._record_memory_history()\n",
    "\n",
    "# Create a test tensor to ensure something gets recorded\n",
    "print(\"Creating test tensor...\")\n",
    "test_tensor = torch.randn(1000, 1000).cuda()\n",
    "print(f\"Test tensor created, memory allocated: {torch.cuda.memory_allocated() / 1024**3:.3f} GB\")\n",
    "\n",
    "# Your existing code here...\n",
    "# ... your training code ...\n",
    "\n",
    "# Before dumping, check if there's any recorded history\n",
    "try:\n",
    "    snapshot = torch.cuda.memory._snapshot()\n",
    "    print(f\"Snapshot contains {len(snapshot.get('traces', []))} traces\")\n",
    "\n",
    "    # Dump to file\n",
    "    torch.cuda.memory._dump_snapshot(\"debug_memory_trace.pickle\")\n",
    "    print(\"Snapshot dumped to file\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating snapshot: {e}\")\n",
    "\n",
    "# Disable recording\n",
    "torch.cuda.memory._record_memory_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "d = 100\n",
    "\n",
    "A = torch.randn(batch, d, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch outer product\n",
    "A_out = torch.einsum(\"bi,bj->bij\", A, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_out_mean = A_out.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2634e+00, -2.6464e-01,  1.8185e-01,  ..., -6.5764e-02,\n",
       "         -3.6784e-01, -7.1913e-02],\n",
       "        [-2.6464e-01,  1.3255e+00,  7.4584e-04,  ...,  2.5179e-01,\n",
       "         -4.0879e-01, -1.2299e-01],\n",
       "        [ 1.8185e-01,  7.4584e-04,  1.0283e+00,  ..., -3.0263e-01,\n",
       "         -5.8569e-02,  1.7342e-01],\n",
       "        ...,\n",
       "        [-6.5764e-02,  2.5179e-01, -3.0263e-01,  ...,  9.6525e-01,\n",
       "         -2.2347e-01, -6.7726e-02],\n",
       "        [-3.6784e-01, -4.0879e-01, -5.8569e-02,  ..., -2.2347e-01,\n",
       "          1.5817e+00,  7.9668e-03],\n",
       "        [-7.1913e-02, -1.2299e-01,  1.7342e-01,  ..., -6.7726e-02,\n",
       "          7.9668e-03,  6.3061e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_out_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_out_mean_2 = A.T @ A / batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_out_mean.allclose(A_out_mean_2, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_out_3 = torch.einsum(\"bi,bj->ij\", A, A) / batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_out_3.allclose(A_out_mean_2, atol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
